{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Model Training and Evaluation**"
      ]
    },
    {
      "source": [
        "<p style=\"text-align: center;\">\n",
        "    <img style=\"width: 35%; height: 20%; float: left;\" src=\"../assets/images/model_training.jpg\" alt=\"Model Training image\">\n",
        "</p>"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Accomplish second business requirement:\n",
        "\n",
        "  _**\"The client is interested in predicting if a cherry leaf is healthy or contains powdery mildew\"**_\n",
        "\n",
        "## Inputs Required\n",
        "\n",
        "* Image data will be sourced from the following directories and their subfolders:\n",
        "\n",
        "  - **Training Images**: inputs/cherry_leaves_dataset/cherry-leaves/train\n",
        "  - **Validation Images**: inputs/cherry_leaves_dataset/cherry-leaves/validation\n",
        "  - **Test Images**: inputs/cherry_leaves_dataset/cherry-leaves/test \n",
        "\n",
        "* av_image_shape.pkl file from outputs/version folder\n",
        "\n",
        "## Generated Outputs\n",
        "\n",
        "1. Images distribution plot in train, validation, and test set.\n",
        "2. Image augmentation.\n",
        "3. Class indices to change prediction inference in labels.\n",
        "4. Optimal best Hyperparameters.\n",
        "5. Machine learning model creation and training.\n",
        "6. Saved best model.\n",
        "7. Learning curve plot for model performance.\n",
        "8. Model evaluation on pickle file.\n",
        "9. Prediction on the random image file.\n"
      ]
    },
    {
      "source": [
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Set up the working environment"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib as mpl\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
        "from matplotlib.image import imread\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "print(\"\\033[92mLibraries Imported Successfully!\\033[0m\")"
      ]
    },
    {
      "source": [
        "**Important libraries and packages required for model creation:**"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "! pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import keras_tuner as kt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.regularizers import l2\n",
        "print(\"\\033[92mLibraries Imported Successfully!\\033[0m\")"
      ]
    },
    {
      "source": [
        "# Change working directory"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "* To maintain a straightforward folder structure for the application, we must navigate from the current folder to its parent folder by using `os.getcwd()` to access the current directory."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "source": [
        "* To update the current directory to its parent directory, follow these steps:\n",
        "\n",
        "  * Use `os.path.dirname()` to obtain the parent directory.\n",
        "  * Utilize `os.chdir()` to set the new current directory to the parent directory."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(f\"\\033[92mYou set a new current directory\\033[0m\")"
      ]
    },
    {
      "source": [
        "* Confirm the new current directory."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_current_dir = os.getcwd()\n",
        "new_current_dir"
      ]
    },
    {
      "source": [
        "# Set input and output directory paths"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "**Inputs**"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = 'inputs/cherry_leaves_dataset/cherry-leaves'\n",
        "train_path = data_dir + '/train'\n",
        "validation_path = data_dir + '/validation'\n",
        "test_path = data_dir + '/test'"
      ]
    },
    {
      "source": [
        "**Outputs**"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "version = 'V_1'\n",
        "\n",
        "file_path = f'outputs/{version}'\n",
        "version_file_path = os.path.join(new_current_dir, file_path)\n",
        "\n",
        "if os.path.exists(version_file_path):\n",
        "    # check version file path exists, if not creates a new directory.\n",
        "     print(f\"\\033[91mVersion {version} already exists. Create a new version please! \\033[0m\")\n",
        "     pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)\n",
        "    print(f\"\\033[92mVersion {version} created successfully! \\033[0m\")"
      ]
    },
    {
      "source": [
        "# Set label names"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "labels = os.listdir(train_path)\n",
        "print('Labels for the images are:', labels)"
      ]
    },
    {
      "source": [
        "# Set image shape"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import saved image shape embedding\n",
        "version = 'V_1'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/av_image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "source": [
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Generating image distribution and count for different sets and labels."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_image_count(folder, label):\n",
        "    \"\"\"\n",
        "    Function to get image count for each label in a specific set\n",
        "    and plot image data distribution.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return len(os.listdir(os.path.join(data_dir, folder, label)))\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Create a DataFrame to store the image distribution and count per set and label\n",
        "sets = ['train', 'validation', 'test']\n",
        "labels = ['healthy', 'powdery_mildew']\n",
        "data = {\n",
        "    'Set': [],\n",
        "    'Label': [],\n",
        "    'Count': []\n",
        "}\n",
        "\n",
        "for folder in sets:\n",
        "    for label in labels:\n",
        "        count = get_image_count(folder, label)\n",
        "        data['Set'].append(folder)\n",
        "        data['Label'].append(label)\n",
        "        data['Count'].append(count)\n",
        "\n",
        "df_freq = pd.DataFrame(data)\n",
        "\n",
        "# Print the image distribution and count per set and label\n",
        "for folder in sets:\n",
        "    print(f\"\\033[1m{folder.capitalize()} set:\\033[0m\")\n",
        "    print(df_freq[df_freq['Set']==folder].to_string(index=False, header=False, justify='center'))\n",
        "    print(\"\\n\")\n",
        "\n",
        "# Plot the image distribution and count per set and label using Seaborn\n",
        "plt.figure(figsize=(10, 5))\n",
        "sns.set_style(\"whitegrid\")\n",
        "sns.barplot(data=df_freq, x='Set', y='Count', hue='Label', palette=['#1f77b4', '#d62728'])\n",
        "sns.despine()\n",
        "plt.savefig(f'{file_path}/img_distribution.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "source": [
        "**Interpretation & Insights:**\n",
        "\n",
        "* In the bar plot representation, the 'healthy' category is indicated by the blue bars, while the 'powdery mildew' category is represented by the red bars.\n",
        "* Within the train dataset, a majority of the data is contained, comprising a total of 2944 image data files. This substantial portion is further segregated into subfolders, with 'healthy' and 'powdery mildew' categories each containing 1472 image files.\n",
        "* The validation set consists of 420 image data files, equally divided into subfolders containing 210 files each for 'healthy' and 'powdery mildew.'\n",
        "* Likewise, the test set encompasses 844 image data files, and these, too, are evenly distributed into subfolders, with 422 files in each category.\n",
        "\n",
        "The visualization provides a comprehensive overview of the dataset distribution across different subsets. This meticulous data distribution adheres to the prescribed 70-10-20 split ratio for training, validation, and testing."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Image Data Augmentation"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "As observed from the metrics above, the dataset is relatively small when compared to large-scale image datasets commonly used for training CNNs. Despite its size, training a CNN with this dataset is possible, but it may be prone to overfitting. To address this issue, we will employ data augmentation techniques to artificially expand the training set."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create an ImageDataGenerator for data augmentation\n",
        "augmented_image_data = ImageDataGenerator(\n",
        "    rotation_range=20,        # Random rotation up to 20 degrees\n",
        "    width_shift_range=0.15,    # Randomly shift images horizontally by 15% of the total width\n",
        "    height_shift_range=0.15,   # Randomly shift images vertically by 15% of the total height\n",
        "    shear_range=0.1,          # Apply shear transformation with maximum shear of 0.1\n",
        "    zoom_range=0.20,           # Randomly zoom images by up to 20%\n",
        "    horizontal_flip=True,     # Randomly flip images horizontally\n",
        "    vertical_flip=True,       # Randomly flip images vertically\n",
        "    fill_mode='nearest',      # Fill points outside the input boundaries using the nearest pixel value\n",
        "    rescale=1./255            # Rescale pixel values to the range [0, 1]\n",
        ")"
      ]
    },
    {
      "source": [
        "* Setting batch size, color mode, and class mode for image data generator."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "data_color_mode = 'rgb'\n",
        "data_class_mode = 'binary'"
      ]
    },
    {
      "source": [
        "## Augment Training Dataset Images"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "train_set = augmented_image_data.flow_from_directory(train_path,\n",
        "                                               target_size=image_shape[:2],\n",
        "                                               color_mode=data_color_mode,\n",
        "                                               batch_size=batch_size,\n",
        "                                               class_mode=data_class_mode,\n",
        "                                               shuffle=True\n",
        "                                               )\n",
        "\n",
        "train_set.class_indices"
      ]
    },
    {
      "source": [
        "## Augment Validation Dataset Images"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_path,\n",
        "                                                                        target_size=image_shape[:2],\n",
        "                                                                        color_mode=data_color_mode,\n",
        "                                                                        batch_size=batch_size,\n",
        "                                                                        class_mode=data_class_mode,\n",
        "                                                                        shuffle=False\n",
        "                                                                        )\n",
        "\n",
        "validation_set.class_indices"
      ]
    },
    {
      "source": [
        "## Augment Test Dataset Images"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  color_mode=data_color_mode,\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode=data_class_mode,\n",
        "                                                                  shuffle=False\n",
        "                                                                  )\n",
        "\n",
        "test_set.class_indices"
      ]
    },
    {
      "source": [
        "## Plot Augmented Image"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_augmented_images(dataset_name, dataset, display_size=3):\n",
        "    \"\"\"\n",
        "    Plot augmented images from the given dataset.\n",
        "    \"\"\"\n",
        "\n",
        "    # Display the number of augmented images\n",
        "    for _ in range(display_size):\n",
        "        # Get the next batch of images and corresponding labels\n",
        "        img, label = dataset.next()\n",
        "\n",
        "        # Display the image\n",
        "        plt.imshow(img[0])  # Selecting the first image from the batch\n",
        "        plt.axis('off')     # Turn off axis ticks and labels\n",
        "        plt.title(f\"{dataset_name} - Augmented Image\")\n",
        "        plt.show()"
      ]
    },
    {
      "source": [
        "* ## Training Image Set"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_augmented_images(\"Train Set\", train_set, display_size=2)"
      ]
    },
    {
      "source": [
        "* ## Validation Image Set"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_augmented_images(\"Validation Set\", validation_set, display_size=2)"
      ]
    },
    {
      "source": [
        "* ## Test Image Set"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_augmented_images(\"Test Set\", test_set, display_size=2)"
      ]
    },
    {
      "source": [
        "Save the class indices for both the labels into a pickle file."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")\n",
        "train_set.class_indices"
      ]
    },
    {
      "source": [
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# CNN ML Model Creation"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "For the image classification task, we employ a Convolutional Neural Network (CNN) as the model of choice. This CNN is specifically designed to learn and identify the predominant feature, which in this case is the powdery mildew, from the pre-labeled cherry leaf images."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "### Function to create the model.\n",
        "\n",
        "The objective of the function `create_model` is to construct model with different hyperparameter configurations for hyperparameter optimization. The aim is to create a compact and accurate model tailored for the specific task at hand.\n",
        "\n",
        "The model architecture comprises a sequence of `Conv2D (convolutional layers)` followed by `MaxPooling2D (max pooling layers)`, which reduce the spatial dimensions of the output feature maps. The number of filters in the convolutional layers progressively increases from 8 to 32 in each subsequent layer. The activation function employed in these convolutional layers is `ReLU`, introducing non-linearity to the network.\n",
        "\n",
        "Following the convolutional layers, the output feature maps are `Flatten (flattened)` and inputted into a fully connected (dense) layer. The number of units in this `Dense layer` is determined by the hyperparameter called 'tune_units,' using the 'hp.Int' method. This hyperparameter search technique allows the network to explore different numbers of units for the dense layer to find the optimal value. The activation function utilized in the dense layer is also ReLU.\n",
        "\n",
        "To mitigate overfitting, a dropout layer with a rate of 0.5 is introduced after the dense layer. The output layer employs the `tanh` activation function, which is a suitable alternative to sigmoid for binary classification tasks. Additionally, the learning rate utilized for training the network is a hyperparameter chosen through the 'learning_rate' variable using the 'hp.Choice' method. The `Adam` optimizer is employed to minimize the binary cross-entropy loss function."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_model(hp):\n",
        "\n",
        "    # Define a Sequential model    \n",
        "    model = Sequential()\n",
        "\n",
        "    # Add a convolutional layer with 12 filters, a kernel size of 3x3, and 'relu' activation function\n",
        "    model.add(Conv2D(filters=8, kernel_size=(3,3), input_shape=image_shape, activation='relu'))\n",
        "    # Add a max pooling layer with a pool size of 2x2\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    # Add another convolutional layer with 24 filters, a kernel size of 3x3, and 'relu' activation function\n",
        "    model.add(Conv2D(filters=16, kernel_size=(3,3), input_shape=image_shape, activation='relu'))\n",
        "    # Add another max pooling layer with a pool size of 2x2\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    # Add another convolutional layer with 36 filters, a kernel size of 3x3, and 'relu' activation function\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=image_shape, activation='relu'))\n",
        "    # Add another max pooling layer with a pool size of 2x2\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    # Flatten the output matrix from the convolutional layers into a vector \n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Tune number of units in Dense layer\n",
        "    opt_units = hp.Int('units', min_value=16, max_value=80, step=16)\n",
        "\n",
        "    # Add a dense layer with tune_units and tune_activation function\n",
        "    model.add(Dense(units=opt_units, activation='relu', kernel_regularizer=l2(0.001)))\n",
        "\n",
        "    # Add a dropout layer with a rate of 0.5\n",
        "    model.add(Dropout(0.5))\n",
        "    # Add a dense output layer with 1 unit and 'sigmoid' activation function\n",
        "    model.add(Dense(units=1, activation='tanh'))\n",
        "\n",
        "    # Define the learning rate and compile the model\n",
        "    opt_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4])\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=opt_learning_rate),\n",
        "        loss=\"binary_crossentropy\",  \n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "\n",
        "    return model\n",
        "    "
      ]
    },
    {
      "source": [
        "Hyperparameter tuning will be performed using the Hyperband tuner, which has been chosen due to its fast processing speed, early stopping capability, and efficient resource utilization. The Hyperband tuner is well-suited for optimizing the hyperparameters of the model by iteratively training different configurations and discarding unpromising ones. Its ability to make intelligent early stopping decisions ensures that only the most promising hyperparameter configurations are explored further, making the tuning process efficient and effective.\n",
        "\n",
        "* Hyperband is a more advanced hyperparameter optimization technique that uses a combination of random search and early stopping."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "tuner = kt.Hyperband(create_model,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory=file_path,\n",
        "                     project_name='hypertuning'\n",
        "                     )"
      ]
    },
    {
      "source": [
        "* Define callbacks\n",
        "\n",
        "  * `Model Checkpointing`: allows to save the model's weights or the entire model to disk at certain intervals or when specific conditions are met (e.g., the validation accuracy improves). This is essential to save the best model so that it can be used later for predictions or further training.\n",
        "  * `Early Stopping`: The EarlyStopping callback is used to stop the training process early when the model's performance on a validation metric stops improving or starts degrading. This helps prevent overfitting and saves time by terminating training when further improvement is unlikely."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the EarlyStopping callback to monitor validation loss, stop after 4 epochs with no improvement, and restore the weights of the best model\n",
        "early_stop = EarlyStopping(monitor='val_loss',\n",
        "                           patience=4,\n",
        "                           verbose=1,\n",
        "                           mode='min',\n",
        "                           restore_best_weights=True\n",
        "                           )\n",
        "# Define the ModelCheckpoint callback to save the best model based on validation accuracy\n",
        "checkpoint = ModelCheckpoint(filepath=os.path.join(file_path, 'best_ml_model.h5'),\n",
        "                             monitor='val_accuracy',\n",
        "                             save_best_only=True,\n",
        "                             mode='max',\n",
        "                             verbose=1\n",
        "                             )"
      ]
    },
    {
      "source": [
        "* Search optimal hyperparameters"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "tuner.search(train_set,\n",
        "             epochs=15,\n",
        "             steps_per_epoch=len(train_set.classes) // batch_size,\n",
        "             validation_data=validation_set,\n",
        "             callbacks=[early_stop, checkpoint],\n",
        "             verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "best_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Display the results of the hyperparameter search\n",
        "print(\"The hyperparameter search is completed!\")\n",
        "print(\"After exploring various configurations, the best model has been found.\")\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_units = best_hyperparameters.get('units')\n",
        "best_lr = best_hyperparameters.get('learning_rate')\n",
        "\n",
        "# Format and print the results\n",
        "print(f\"The optimal number of units in the first densely-connected layer is \\033[1m{best_units}\\033[0m.\")\n",
        "print(f\"The optimal learning rate for the optimizer is \\033[1m{best_lr:.4f}\\033[0m.\")  # Round to 4 decimal places\n",
        "print(\"Now we can use these hyperparameters to train the final model.\")"
      ]
    },
    {
      "source": [
        "* Create model using best optimal hyperparameters"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tuner.hypermodel.build(best_hyperparameters)"
      ]
    },
    {
      "source": [
        "* Model Summary"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "source": [
        "**Interpretation:**\n",
        "\n",
        "* The provided summary represents a sequential model architecture designed for data analysis. \n",
        "* It consists of various layers, such as convolutional, pooling, and dense layers, flatten and dropout that transform input data and train the model.\n",
        "* The model has a total of 2,602,925 parameters, which contribute to its ability to learn from data. This is a big number of data to achieve excellent results for our model.\n",
        "* This architecture aims to process visual information and make predictions, making it a valuable tool for understanding patterns within images."
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "* Fit the model "
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "history_df = model.fit(train_set,\n",
        "                    epochs=20,\n",
        "                    steps_per_epoch=len(train_set.classes) // batch_size,\n",
        "                    validation_data=validation_set,\n",
        "                    callbacks=[early_stop, checkpoint],\n",
        "                    verbose=1)"
      ]
    },
    {
      "source": [
        "---"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "# Model Performance and Metrics"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "source": [
        "* Model Learning Curve"
      ],
      "cell_type": "markdown",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(history_df.history)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "losses[['loss', 'val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f'{file_path}/model_training_losses.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f'{file_path}/model_training_acc.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python381264bit3812pyenv0d43abce8dd94f47923d4d2332621797"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12-final"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}